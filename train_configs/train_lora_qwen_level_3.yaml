pretrained_model_name_or_path: Qwen/Qwen-Image
data_config:
  base_dir: ./ColorBench-v1/Finetune_LevelALL_Sets
  prompt_levels: [3]
  color_levels: [1, 2, 3]
  split: train
  train_batch_size: 8
  num_workers: 4
  img_size: 384
  caption_dropout_rate: 0.1
  random_ratio: false # support multi crop preprocessing
  caption_type: txt
report_to: wandb
train_batch_size: 8
output_dir: ./lora_saves_level_3
max_train_steps: 3000
learning_rate: 3e-4
lr_scheduler: constant
lr_warmup_steps: 0
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 0.01
adam_epsilon: 1e-8
max_grad_norm: 1.0
logging_dir: logs
mixed_precision: "bf16"
checkpointing_steps: 100
checkpoints_total_limit: 100
tracker_project_name: qwen_image_lora
resume_from_checkpoint: latest
gradient_accumulation_steps: 1
lora_rank: 16
lora_alpha: 32
lora_dropout: 0.1
precompute_text_embeddings: true
precompute_image_embeddings: true
quantize: true
adam8bit: true
save_cache_on_disk: true
